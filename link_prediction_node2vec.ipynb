{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTf6T_V-SDS7"
      },
      "source": [
        "# Assignment 2 : link_prediction\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLHxopXPTa6"
      },
      "source": [
        "## Download Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zKeKY2J7PD1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dbae5cd-d09d-40c8-88cd-d0b41a8b065e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 48 kB 2.2 MB/s \n",
            "\u001b[?25h  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.1 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install torch geometric\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iYEkdXj1GST8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05c55de-511f-4184-c6c3-b61080a00b03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.14-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.9-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 43.6 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=43f5cfa1712e52245581b4f3172493a7702444cf97065d51b971dc57cb025161\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.9 setproctitle-1.2.2 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.14\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5sHXKNb7Dmt",
        "outputId": "6ce7db5d-4d5f-4908-c927-ee93a252abdb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-cluster==1.5.9\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 2.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7YoIHpeAKO7"
      },
      "source": [
        "## Import Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zspciFpXPd-R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear\n",
        "import csv\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "import wandb\n",
        "from sklearn.metrics import f1_score\n",
        "from torch_geometric.nn import GCNConv\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset "
      ],
      "metadata": {
        "id": "6y66NZIMI6tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yRXpXtGpJWbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5269b5f6-5cbc-466f-af72-4ded1304cf74"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = 1\n",
        "train1_path = f\"/content/drive/My Drive/dataset/dataset{d}/train.csv\"\n",
        "test1_path = f\"/content/drive/My Drive/dataset/dataset{d}/test.csv\"\n",
        "content_path = f\"/content/drive/My Drive/dataset/dataset{d}/content.csv\"\n",
        "epocht= 5000\n"
      ],
      "metadata": {
        "id": "kHtrLoq0eeMO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "class load_data(): \n",
        "  def __init__(self, path, attr_path):\n",
        "    super(load_data,self).__init__()    \n",
        "    self.path = path\n",
        "    self.attr_path = attr_path\n",
        "\n",
        "  def read_data(self):\n",
        "      file = pd.read_csv(self.path)\n",
        "      label = file.loc[:,'label'].values\n",
        "      bilabel = []\n",
        "      bilabel.extend(label)\n",
        "      bilabel.extend(label)\n",
        "      bilabel= np.array(bilabel)\n",
        "      edgeto = file.loc[:,'to'].values\n",
        "      edgefrom = file.loc[:,'from'].values\n",
        "\n",
        "      edge_index = [[],[]]\n",
        "      pos_edge_index = [[],[]]\n",
        "      neg_edge_index = [[],[]]\n",
        "      non_zero = np.nonzero(np.array(label))[0]\n",
        "\n",
        "      edge_index[0].extend(edgeto)\n",
        "      edge_index[1].extend(edgefrom)\n",
        "      edge_index[1].extend(edgeto)\n",
        "      edge_index[0].extend(edgefrom)\n",
        "      edge_index = torch.tensor(edge_index)\n",
        "      # positive\n",
        "      pos_edge_index[0].extend(edgeto[non_zero])\n",
        "      pos_edge_index[1].extend(edgefrom[non_zero])\n",
        "      pos_edge_index[1].extend(edgeto[non_zero])\n",
        "      pos_edge_index[0].extend(edgefrom[non_zero])\n",
        "      pos_edge_index = torch.tensor(pos_edge_index)\n",
        "\n",
        "      # negative\n",
        "      neg_edge_index[0].extend(edgeto[~non_zero])\n",
        "      neg_edge_index[1].extend(edgefrom[~non_zero])\n",
        "      neg_edge_index[1].extend(edgeto[~non_zero])\n",
        "      neg_edge_index[0].extend(edgefrom[~non_zero])\n",
        "      neg_edge_index = torch.tensor(pos_edge_index)\n",
        "\n",
        "      return edge_index, pos_edge_index, neg_edge_index, bilabel\n",
        "\n",
        "\n",
        "  def read_content(self):\n",
        "      attribution = []; node=[]\n",
        "      content = pd.read_csv(self.attr_path,delimiter='\\t',header=None)\n",
        "      contentArray = content.values\n",
        "      attribute = contentArray[contentArray[:, 0].argsort()]\n",
        "      np.set_printoptions(threshold=sys.maxsize)\n",
        "      for i in attribute:\n",
        "        n = i[0]\n",
        "        x = i[1:]\n",
        "        attribution.append(x)\n",
        "        node.append(n)\n",
        "      attribution = torch.tensor(attribution, dtype= torch.float)\n",
        "      node_num = np.shape(node)[0]\n",
        "      print(node_num)\n",
        "      return attribution, node_num\n"
      ],
      "metadata": {
        "id": "FyWUk3xrIuKH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Dt = load_data(train1_path,content_path)\n",
        "edge_index, pos_edge, neg_edge,  label = Dt.read_data()\n",
        "attribution, node_num = Dt.read_content()\n",
        "data = Data(x=attribution, edge_index = edge_index, pos_edge_index=pos_edge, neg_edge_index=neg_edge, y =label, num_nodes = node_num)\n",
        "\n",
        "attr = data.x\n",
        "print(np.shape(attr[0])[0])"
      ],
      "metadata": {
        "id": "HqvzoRIjMG6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5db086-5713-4703-b0f4-110898a9bfb7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2708\n",
            "1433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepWalk"
      ],
      "metadata": {
        "id": "iYOUzHG-oI9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm import tqdm\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "class DeepWalk:\n",
        "    def __init__(self, window_size: int, embedding_size: int, walk_length: int, walks_per_node: int):\n",
        "        \"\"\"\n",
        "        :param window_size: window size for the Word2Vec model\n",
        "        :param embedding_size: size of the final embedding\n",
        "        :param walk_length: length of the walk\n",
        "        :param walks_per_node: number of walks per node\n",
        "        \"\"\"\n",
        "        self.window_size = window_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.walk_length = walk_length\n",
        "        self.walk_per_node = walks_per_node\n",
        "\n",
        "    def random_walk(self, g: nx.Graph, start: str, use_probabilities: bool = False) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate a random walk starting on start\n",
        "        :param g: Graph\n",
        "        :param start: starting node for the random walk\n",
        "        :param use_probabilities: if True take into account the weights assigned to each edge to select the next candidate\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        walk = [start]\n",
        "        for i in range(self.walk_length):\n",
        "            neighbours = g.neighbors(walk[i])\n",
        "            neighs = list(neighbours)\n",
        "            if use_probabilities:\n",
        "                probabilities = [g.get_edge_data(walk[i], neig)[\"weight\"] for neig in neighs]\n",
        "                sum_probabilities = sum(probabilities)\n",
        "                probabilities = list(map(lambda t: t / sum_probabilities, probabilities))\n",
        "                p = np.random.choice(neighs, p=probabilities)\n",
        "            else:\n",
        "                p = random.choice(neighs)\n",
        "            walk.append(p)\n",
        "        return walk\n",
        "\n",
        "    def get_walks(self, g: nx.Graph, use_probabilities: bool = False) -> List[List[str]]:\n",
        "        \"\"\"\n",
        "        Generate all the random walks\n",
        "        :param g: Graph\n",
        "        :param use_probabilities:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        random_walks = []\n",
        "        for _ in range(self.walk_per_node):\n",
        "            random_nodes = list(g.nodes)\n",
        "            random.shuffle(random_nodes)\n",
        "            for node in tqdm(random_nodes):\n",
        "                random_walks.append(self.random_walk(g=g, start=node, use_probabilities=use_probabilities))\n",
        "        return random_walks\n",
        "\n",
        "    def compute_embeddings(self, walks: List[List[str]]):\n",
        "        \"\"\"\n",
        "        Compute the node embeddings for the generated walks\n",
        "        :param walks: List of walks\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        model = Word2Vec(sentences=walks, window=self.window_size, vector_size=self.embedding_size)\n",
        "        return model.wv"
      ],
      "metadata": {
        "id": "2ywg-cmFoIf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node2Vec"
      ],
      "metadata": {
        "id": "ynkTrrQ-movT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## first try"
      ],
      "metadata": {
        "id": "3iqHzZ_QNMdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3BQFoRjsNMXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Embedding\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_sparse import SparseTensor\n",
        "import torch_cluster  # noqa\n",
        "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
        "\n",
        "import torch_cluster  # noqa\n",
        "random_walk = torch.ops.torch_cluster.random_walk\n",
        "# except ImportError:\n",
        "#     random_walk = None\n",
        "\n",
        "EPS = 1e-15\n",
        "\n",
        "\n",
        "class Node2Vec(torch.nn.Module):\n",
        "    r\"\"\"The Node2Vec model from the\n",
        "    `\"node2vec: Scalable Feature Learning for Networks\"\n",
        "    <https://arxiv.org/abs/1607.00653>`_ paper where random walks of\n",
        "    length :obj:`walk_length` are sampled in a given graph, and node embeddings\n",
        "    are learned via negative sampling optimization.\n",
        "\n",
        "    .. note::\n",
        "\n",
        "        For an example of using Node2Vec, see `examples/node2vec.py\n",
        "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
        "        node2vec.py>`_.\n",
        "\n",
        "    Args:\n",
        "        edge_index (LongTensor): The edge indices.\n",
        "        embedding_dim (int): The size of each embedding vector.\n",
        "        walk_length (int): The walk length.\n",
        "        context_size (int): The actual context size which is considered for\n",
        "            positive samples. This parameter increases the effective sampling\n",
        "            rate by reusing samples across different source nodes.\n",
        "        walks_per_node (int, optional): The number of walks to sample for each\n",
        "            node. (default: :obj:`1`)\n",
        "        p (float, optional): Likelihood of immediately revisiting a node in the\n",
        "            walk. (default: :obj:`1`)\n",
        "        q (float, optional): Control parameter to interpolate between\n",
        "            breadth-first strategy and depth-first strategy (default: :obj:`1`)\n",
        "        num_negative_samples (int, optional): The number of negative samples to\n",
        "            use for each positive sample. (default: :obj:`1`)\n",
        "        num_nodes (int, optional): The number of nodes. (default: :obj:`None`)\n",
        "        sparse (bool, optional): If set to :obj:`True`, gradients w.r.t. to the\n",
        "            weight matrix will be sparse. (default: :obj:`False`)\n",
        "    \"\"\"\n",
        "    def __init__(self, edge_index, embedding_dim, walk_length, context_size,\n",
        "                 walks_per_node=1, p=1, q=1, num_negative_samples=1,\n",
        "                 num_nodes=None, sparse=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # if random_walk is None:\n",
        "        #     raise ImportError('`Node2Vec` requires `torch-cluster`.')\n",
        "\n",
        "        N = maybe_num_nodes(edge_index, num_nodes)\n",
        "        row, col = edge_index\n",
        "        self.adj = SparseTensor(row=row, col=col, sparse_sizes=(N, N))\n",
        "        self.adj = self.adj.to('cpu')\n",
        "\n",
        "        assert walk_length >= context_size\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.walk_length = walk_length - 1\n",
        "        self.context_size = context_size\n",
        "        self.walks_per_node = walks_per_node\n",
        "        self.p = p\n",
        "        self.q = q\n",
        "        self.num_negative_samples = num_negative_samples\n",
        "\n",
        "        self.embedding = Embedding(N, embedding_dim, sparse=sparse)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.embedding.reset_parameters()\n",
        "\n",
        "\n",
        "    def forward(self, batch=None):\n",
        "        \"\"\"Returns the embeddings for the nodes in :obj:`batch`.\"\"\"\n",
        "        emb = self.embedding.weight\n",
        "        return emb if batch is None else emb.index_select(0, batch)\n",
        "\n",
        "    def loader(self, **kwargs):\n",
        "        return DataLoader(range(self.adj.sparse_size(0)),\n",
        "                          collate_fn=self.sample, **kwargs)\n",
        "\n",
        "\n",
        "    def pos_sample(self, batch):\n",
        "        batch = batch.repeat(self.walks_per_node)\n",
        "        rowptr, col, _ = self.adj.csr()\n",
        "        rw = random_walk(rowptr, col, batch, self.walk_length, self.p, self.q)\n",
        "        if not isinstance(rw, torch.Tensor):\n",
        "            rw = rw[0]\n",
        "\n",
        "        walks = []\n",
        "        num_walks_per_rw = 1 + self.walk_length + 1 - self.context_size\n",
        "        for j in range(num_walks_per_rw):\n",
        "            walks.append(rw[:, j:j + self.context_size])\n",
        "        return torch.cat(walks, dim=0)\n",
        "\n",
        "\n",
        "    def neg_sample(self, batch):\n",
        "        batch = batch.repeat(self.walks_per_node * self.num_negative_samples)\n",
        "\n",
        "        rw = torch.randint(self.adj.sparse_size(0),\n",
        "                           (batch.size(0), self.walk_length))\n",
        "        rw = torch.cat([batch.view(-1, 1), rw], dim=-1)\n",
        "\n",
        "        walks = []\n",
        "        num_walks_per_rw = 1 + self.walk_length + 1 - self.context_size\n",
        "        for j in range(num_walks_per_rw):\n",
        "            walks.append(rw[:, j:j + self.context_size])\n",
        "        return torch.cat(walks, dim=0)\n",
        "\n",
        "\n",
        "    def sample(self, batch):\n",
        "        if not isinstance(batch, torch.Tensor):\n",
        "            batch = torch.tensor(batch)\n",
        "        return self.pos_sample(batch), self.neg_sample(batch)\n",
        "\n",
        "\n",
        "    def loss(self, pos_rw, neg_rw):\n",
        "        r\"\"\"Computes the loss given positive and negative random walks.\"\"\"\n",
        "\n",
        "        # Positive loss.\n",
        "        start, rest = pos_rw[:, 0], pos_rw[:, 1:].contiguous()\n",
        "\n",
        "        h_start = self.embedding(start).view(pos_rw.size(0), 1,\n",
        "                                             self.embedding_dim)\n",
        "        h_rest = self.embedding(rest.view(-1)).view(pos_rw.size(0), -1,\n",
        "                                                    self.embedding_dim)\n",
        "\n",
        "        out = (h_start * h_rest).sum(dim=-1).view(-1)\n",
        "        pos_loss = -torch.log(torch.sigmoid(out) + EPS).mean()\n",
        "\n",
        "        # Negative loss.\n",
        "        start, rest = neg_rw[:, 0], neg_rw[:, 1:].contiguous()\n",
        "\n",
        "        h_start = self.embedding(start).view(neg_rw.size(0), 1,\n",
        "                                             self.embedding_dim)\n",
        "        h_rest = self.embedding(rest.view(-1)).view(neg_rw.size(0), -1,\n",
        "                                                    self.embedding_dim)\n",
        "\n",
        "        out = (h_start * h_rest).sum(dim=-1).view(-1)\n",
        "        neg_loss = -torch.log(1 - torch.sigmoid(out) + EPS).mean()\n",
        "\n",
        "        return pos_loss + neg_loss\n",
        "\n",
        "\n",
        "    def test(self, train_z, train_y, test_z, test_y, solver='lbfgs',\n",
        "             multi_class='auto', *args, **kwargs):\n",
        "        r\"\"\"Evaluates latent space quality via a logistic regression downstream\n",
        "        task.\"\"\"\n",
        "        from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "        clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n",
        "                                 **kwargs).fit(train_z.detach().cpu().numpy(),\n",
        "                                               train_y.detach().cpu().numpy())\n",
        "        return clf.score(test_z.detach().cpu().numpy(),\n",
        "                         test_y.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.embedding.weight.size(0)}, '\n",
        "                f'{self.embedding.weight.size(1)})')"
      ],
      "metadata": {
        "id": "WdFHLk5VCwIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get train test and val sizes: (70% - 15% - 15%)\n",
        "train_size = int(data.num_nodes *0.7)\n",
        "test_size = int(data.num_nodes*0.85) - train_size\n",
        "val_size = data.num_nodes - train_size - test_size"
      ],
      "metadata": {
        "id": "nTbp-VXL1jTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = data.edge_index.t().numpy()\n",
        "# get train test and validation set of nodes\n",
        "train_set = nodes[0:train_size]\n",
        "test_set = nodes[train_size:train_size+test_size]\n",
        "val_set = nodes[train_size+test_size:]\n",
        "\n",
        "print(len(train_set),len(test_set),len(val_set))\n",
        "print(len(train_set)+len(test_set)+len(val_set) == len(nodes))\n",
        "\n",
        "print(\"train set\\t\",train_set[:10])\n",
        "print(\"test set \\t\",test_set[:10])\n",
        "print(\"val set  \\t\",val_set[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am5fBXMJ1yU3",
        "outputId": "e10ff304-a87c-412c-b67e-7175ab35d062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1895 406 15071\n",
            "True\n",
            "train set\t [[2399 2339]\n",
            " [2397 1144]\n",
            " [ 854 1726]\n",
            " [ 872  702]\n",
            " [2450 1312]\n",
            " [ 384 1277]\n",
            " [1808 2472]\n",
            " [  97 1861]\n",
            " [2030 2494]\n",
            " [ 682  100]]\n",
            "test set \t [[ 494  133]\n",
            " [ 485  260]\n",
            " [2114  561]\n",
            " [2092  913]\n",
            " [ 970 1128]\n",
            " [ 130 2541]\n",
            " [ 219  722]\n",
            " [ 692  122]\n",
            " [1473 2222]\n",
            " [1921 1337]]\n",
            "val set  \t [[1772  199]\n",
            " [2563  394]\n",
            " [2420  761]\n",
            " [2474 1044]\n",
            " [2263  586]\n",
            " [  76 2685]\n",
            " [1002 2056]\n",
            " [1536 1676]\n",
            " [2067  114]\n",
            " [1993 2038]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(nodes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Bb4Tz32uLd",
        "outputId": "252f440b-0370-4b28-fcc7-4b17c7cd25b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_sparse.tensor import cpu\n",
        "# build test train val masks\n",
        "device = cpu\n",
        "train_mask = torch.zeros(len(nodes),dtype=torch.long)\n",
        "for i in train_set:\n",
        "    train_mask[i] = 1.\n",
        "\n",
        "test_mask = torch.zeros(len(nodes),dtype=torch.long)\n",
        "for i in test_set:\n",
        "    test_mask[i] = 1.\n",
        "    \n",
        "val_mask = torch.zeros(len(nodes),dtype=torch.long)\n",
        "for i in val_set:\n",
        "    val_mask[i] = 1.\n",
        "    \n",
        "print(\"train mask \\t\",train_mask[0:15])\n",
        "print(\"test mask  \\t\",test_mask[0:15])\n",
        "print(\"val mask   \\t\",val_mask[0:15]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1ybE7jr2TWz",
        "outputId": "cc3cc37a-8150-41f2-924b-712b37fb445b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train mask \t tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0])\n",
            "test mask  \t tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "val mask   \t tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "data.val_mask = val_mask"
      ],
      "metadata": {
        "id": "go3WZp6h2553"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch_cluster\n",
        "import os.path as osp\n",
        "import torch\n",
        "import torch_cluster\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from tqdm.notebook import tqdm\n",
        "from torch_geometric.datasets import TUDataset\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n"
      ],
      "metadata": {
        "id": "zy-Xz6b03GPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_cluster  # noqa\n",
        "import torch\n",
        "from torch.nn import Embedding\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_sparse import SparseTensor\n",
        "\n",
        "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
        "\n",
        "random_walk = torch.ops.torch_cluster.random_walk"
      ],
      "metadata": {
        "id": "sF1HNv8e8L00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=20,\n",
        "             context_size=10, walks_per_node=10,\n",
        "             num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
        "\n",
        "\n",
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n",
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xhr5Eq92-r6",
        "outputId": "f607ba5d-8f66-491f-d922-adcc40fe560e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# wandb.init(project=\"Link Prediction_ node2vec\") \n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    time = 0 \n",
        "    for pos_rw, neg_rw in loader:\n",
        "        print(pos_rw, neg_rw)\n",
        "        time +=1\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()                        \n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(1, 200):\n",
        "    min_valid_loss =2\n",
        "    loss = train()\n",
        "    #acc = test()\n",
        "    if epoch % 20 == 0:    \n",
        "      wandb.log({'pair_loss': loss, 'epoch': epoch})   \n",
        "      print(f'epoch: {epoch} / training loss: {loss}')\n",
        "      if min_valid_loss > loss:\n",
        "        min_valid_loss = loss\n",
        "      # Saving State Dict\n",
        "        print(\"________checkpoint save model ______\")\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/dataset/saved_mode_node2vec.pth')\n"
      ],
      "metadata": {
        "id": "S3fM8suP4G5h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e920218f-1a66-4992-87b4-2179200df6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7ff8ba8d9d50>> (for pre_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 441, 1995,  854,  ...,  563, 1840,  556],\n",
            "        [ 521, 2415,  521,  ..., 1641, 1615, 2133],\n",
            "        [1458,    1,  962,  ..., 1061, 2482, 1601],\n",
            "        ...,\n",
            "        [1074, 2187, 1643,  ...,   98, 1300, 1541],\n",
            "        [ 274, 2463,  761,  ..., 2678, 1721, 1408],\n",
            "        [ 243,  763,  982,  ...,  714, 1303,  714]]) tensor([[ 441, 2416, 1184,  ...,  930, 1618,  178],\n",
            "        [ 521,  322,  943,  ..., 1706, 1824, 1557],\n",
            "        [1458,  627, 1546,  ...,  508, 2634,  792],\n",
            "        ...,\n",
            "        [ 437, 2531, 2634,  ..., 1435, 1688, 1678],\n",
            "        [1027, 2458, 1649,  ..., 1843, 2434,  365],\n",
            "        [2417, 1692, 1216,  ..., 1361, 2541, 2266]])\n",
            "tensor([[2692,  451, 1503,  ..., 2529,  993, 2529],\n",
            "        [2615, 1691,  137,  ..., 1575, 2653, 1575],\n",
            "        [2512,  781,  829,  ..., 1568,   81, 1568],\n",
            "        ...,\n",
            "        [1174,  144, 2624,  ..., 1314,  452,   45],\n",
            "        [ 617,  209, 1649,  ..., 1151, 2116, 1151],\n",
            "        [ 499,  330,  499,  ...,  232,  184, 2659]]) tensor([[2692,  992,  305,  ..., 2624, 2643, 1740],\n",
            "        [2615,  192, 2642,  ..., 1862, 1307, 1705],\n",
            "        [2512,  161, 1570,  ...,  420,  319,  893],\n",
            "        ...,\n",
            "        [ 215, 2098, 2158,  ...,  103, 2017, 1399],\n",
            "        [  59, 1518, 1522,  ...,  743,  789, 1111],\n",
            "        [1724, 2538, 2003,  ...,  805,  406, 2659]])\n",
            "tensor([[1798,  827, 1649,  ..., 2678, 2450,  755],\n",
            "        [1812,  474,  511,  ..., 1889, 2105,  982],\n",
            "        [1945,  703,  226,  ..., 2029, 1243, 2029],\n",
            "        ...,\n",
            "        [1561, 1991, 2453,  ..., 2483, 2567, 2522],\n",
            "        [1068, 2247,  354,  ...,  968, 1749,  362],\n",
            "        [2265,  534,  512,  ..., 1268, 1305, 2178]]) tensor([[1798, 2682,   46,  ..., 1531,  497, 1374],\n",
            "        [1812, 1871, 2323,  ...,  327, 2262, 2239],\n",
            "        [1945, 1453,  338,  ..., 1958, 2498,  782],\n",
            "        ...,\n",
            "        [1702,  750, 1781,  ..., 1924, 1995, 1859],\n",
            "        [1535, 2511,  794,  ...,  116,  315, 1359],\n",
            "        [   9,  951, 1328,  ..., 1866,  118, 1412]])\n",
            "tensor([[2375,  188, 1108,  ..., 2115, 1698, 2008],\n",
            "        [ 250, 1009, 2663,  ..., 2672, 2129, 2168],\n",
            "        [2624, 2296, 1986,  ..., 2184,  226, 2184],\n",
            "        ...,\n",
            "        [1013, 2400, 2676,  ..., 1524, 2384, 2360],\n",
            "        [2582, 1685, 1447,  ..., 1724,  945, 1724],\n",
            "        [1676, 1452, 2124,  ..., 1994,  968, 1749]]) tensor([[2375,  375, 1122,  ...,  748,  922, 2163],\n",
            "        [ 250, 1022,  823,  ...,  375,  373, 1996],\n",
            "        [2624, 2662,  698,  ..., 1263, 1544,  671],\n",
            "        ...,\n",
            "        [2427, 1444, 2275,  ...,  147, 1053, 2599],\n",
            "        [1253, 1268, 1003,  ..., 1749, 1994, 1190],\n",
            "        [ 741,  337, 2590,  ..., 1669, 1325, 2229]])\n",
            "tensor([[1642, 1577,  471,  ...,  651, 2535,  651],\n",
            "        [2697,  512, 1987,  ...,  152, 1348,  383],\n",
            "        [2502, 1798, 2146,  ...,  604, 1876, 2129],\n",
            "        ...,\n",
            "        [ 111, 2358, 2263,  ...,  444, 1253,  670],\n",
            "        [1223, 2059, 1605,  ..., 2009,  619, 1129],\n",
            "        [1085, 2465, 1085,  ..., 1615, 1908,  106]]) tensor([[1642, 2330, 1727,  ...,  165, 1718,  310],\n",
            "        [2697, 1484, 2316,  ..., 1066,  572, 1776],\n",
            "        [2502, 1946,  776,  ...,  322,  278, 1108],\n",
            "        ...,\n",
            "        [1758,   62,  668,  ..., 1103,  135, 1850],\n",
            "        [2547, 1060, 1255,  ...,  651, 2644,  332],\n",
            "        [2153, 1060, 2312,  ..., 1224, 2509, 1255]])\n",
            "tensor([[2472, 1808, 1383,  ..., 2384, 1055,  228],\n",
            "        [1219, 1103, 1219,  ..., 2267,  831, 1777],\n",
            "        [  43,  556, 1173,  ..., 1161, 1986, 1253],\n",
            "        ...,\n",
            "        [2307,  394,   15,  ..., 2218, 2424, 2251],\n",
            "        [1966, 2264, 1720,  ..., 1544, 2623, 1544],\n",
            "        [ 268, 1724,  323,  ..., 1467, 1201, 1467]]) tensor([[2472, 1129, 2599,  ...,  375,  293, 1538],\n",
            "        [1219, 1362, 2254,  ..., 2381,   59, 1030],\n",
            "        [  43, 2580, 1168,  ..., 1620, 1393, 1434],\n",
            "        ...,\n",
            "        [1884, 1573, 1339,  ..., 1754,  249, 2494],\n",
            "        [ 418, 2140,  987,  ..., 2601, 1696, 1104],\n",
            "        [  23,  148, 1827,  ..., 2427, 2106,   66]])\n",
            "tensor([[2311,  183, 2423,  ...,  680,  789, 2402],\n",
            "        [1021, 2521, 2162,  ...,  354,  255,  766],\n",
            "        [ 194,  446,  194,  ...,  431,  668, 1911],\n",
            "        ...,\n",
            "        [2471, 2698, 2471,  ...,  777, 1895,  676],\n",
            "        [ 345,  398, 1579,  ...,  354, 2694,  354],\n",
            "        [1659,  646, 1659,  ..., 1953, 1042, 2005]]) tensor([[2311, 1509,  896,  ..., 1758, 2396, 1237],\n",
            "        [1021,  984, 1093,  ..., 1849, 1745, 1850],\n",
            "        [ 194, 2171, 2575,  ..., 1645, 1198, 1069],\n",
            "        ...,\n",
            "        [  20, 1494, 1441,  ...,  812,  570, 1452],\n",
            "        [2358,   55,  635,  ..., 2142,  981, 1924],\n",
            "        [  59, 1321, 2090,  ..., 1683,   19, 1383]])\n",
            "tensor([[2568, 1517, 1405,  ...,  214, 1923, 1792],\n",
            "        [ 399, 2439,  399,  ...,  303,  998,  303],\n",
            "        [ 421,  910, 1634,  ..., 1885,  357, 2165],\n",
            "        ...,\n",
            "        [1352, 2466,  289,  ..., 1005, 1101, 1005],\n",
            "        [ 255, 1084, 2395,  ...,   19, 1945,  189],\n",
            "        [1054, 1306, 1521,  ..., 1762, 2196,  244]]) tensor([[2568,  509,  532,  ..., 1905, 1632, 2370],\n",
            "        [ 399,  912, 1918,  ..., 2581,  474,  354],\n",
            "        [ 421, 1196, 1698,  ..., 1395,  137,  258],\n",
            "        ...,\n",
            "        [1410,  158, 2607,  ...,  549, 1587, 1674],\n",
            "        [ 562,  589, 2092,  ..., 2343,  142,  675],\n",
            "        [  89,  706,  789,  ..., 1805,  426, 2098]])\n",
            "tensor([[1315,  941,  718,  ..., 2451,  213,  954],\n",
            "        [1117, 1434,  118,  ..., 2197,   33, 2222],\n",
            "        [ 328, 1762, 1427,  ..., 1275,  707,  278],\n",
            "        ...,\n",
            "        [1311,  449,   89,  ..., 1557, 2505, 1555],\n",
            "        [ 475, 1598,  542,  ...,   58, 1518, 2503],\n",
            "        [ 614, 1081,   23,  ..., 2701, 1658, 1537]]) tensor([[1315, 2108, 1375,  ...,  130, 1945,   20],\n",
            "        [1117, 1190, 1567,  ..., 1906, 1443, 1351],\n",
            "        [ 328,  295, 1716,  ..., 1007,  661, 2306],\n",
            "        ...,\n",
            "        [  79, 1689,  468,  ...,  629,  350, 2453],\n",
            "        [1420,  978,  628,  ..., 1610,   90, 1537],\n",
            "        [1831, 1641, 1324,  ..., 1114,  190, 1276]])\n",
            "tensor([[1259,   58,   82,  ..., 2244,  209, 1898],\n",
            "        [1294, 2438, 2301,  ...,  510, 2301, 2296],\n",
            "        [ 768, 2205, 2364,  ...,  347, 2080, 1424],\n",
            "        ...,\n",
            "        [2153,  158,   78,  ..., 1171,  495, 2292],\n",
            "        [ 771, 2103, 1792,  ...,  633, 1863, 1432],\n",
            "        [2008, 2568, 2646,  ...,   39, 1819,   34]]) tensor([[1259,  999, 2239,  ..., 1061, 2311,  791],\n",
            "        [1294,  833, 1239,  ..., 1106,  297, 1608],\n",
            "        [ 768,  204, 1936,  ...,  825, 1960,  176],\n",
            "        ...,\n",
            "        [1556, 1884, 1507,  ..., 1705,  492, 2132],\n",
            "        [ 210, 1235, 2311,  ..., 2469, 1648,  801],\n",
            "        [ 310, 1326, 2029,  ..., 1659, 2058, 2323]])\n",
            "tensor([[1456, 1756, 1561,  ..., 2261, 2153,  729],\n",
            "        [1272, 2077,  759,  ..., 1925, 2084, 2371],\n",
            "        [1166,   91, 1119,  ..., 1403,  641,  257],\n",
            "        ...,\n",
            "        [1728, 1942, 1578,  ...,   39, 1233, 2375],\n",
            "        [2252, 1007, 2312,  ...,  901, 2406, 2325],\n",
            "        [ 759, 2010, 2571,  ..., 1755, 1851, 1755]]) tensor([[1456, 2213, 2516,  ...,  781, 2256, 1716],\n",
            "        [1272, 2643, 1660,  ...,   65,  414, 1831],\n",
            "        [1166, 1029, 1775,  ...,  239, 1976, 1241],\n",
            "        ...,\n",
            "        [ 481,  267, 1402,  ..., 2468,   76, 1475],\n",
            "        [2595, 1357,  507,  ..., 1291,  419, 1418],\n",
            "        [1578, 1563, 1025,  ..., 2269,  531,  684]])\n",
            "tensor([[1619,  369, 1916,  ..., 2468, 1769, 2468],\n",
            "        [1096, 2238, 2074,  ...,  138,  793,  138],\n",
            "        [  87,  523, 1860,  ..., 1864,  601, 1864],\n",
            "        ...,\n",
            "        [2011, 1311, 2125,  ...,  432,  947, 2333],\n",
            "        [1254, 1577, 2658,  ..., 1638, 2211, 1082],\n",
            "        [1985,  940, 2476,  ..., 1748,  481, 1035]]) tensor([[1619,  853,  883,  ..., 2124, 2180, 2400],\n",
            "        [1096,  761, 2193,  ...,  503,  901,  189],\n",
            "        [  87, 1163, 1001,  ..., 2258, 1745, 1721],\n",
            "        ...,\n",
            "        [1915,   16,  631,  ..., 1182, 2360, 1410],\n",
            "        [ 948, 1532, 2340,  ..., 2350, 2405, 2159],\n",
            "        [ 962, 2205, 1627,  ...,  546, 2649, 1275]])\n",
            "tensor([[2508, 2278, 2508,  ..., 2579, 2640, 2557],\n",
            "        [2261, 2153, 1494,  ..., 2492,  133,  494],\n",
            "        [2302,  300,  306,  ..., 1335, 2102,  299],\n",
            "        ...,\n",
            "        [2631, 2128, 2631,  ...,  193, 1002, 2252],\n",
            "        [1765,   32, 1509,  ..., 1734, 2104, 2063],\n",
            "        [2546, 2531, 2143,  ..., 1283, 2430,  350]]) tensor([[2508, 1282,  331,  ...,   52, 1445, 2607],\n",
            "        [2261, 1152,  440,  ..., 1798,  233, 2460],\n",
            "        [2302, 1180, 1393,  ..., 1188, 1711, 2687],\n",
            "        ...,\n",
            "        [ 832, 2352,  200,  ..., 2522, 2207, 1889],\n",
            "        [ 865, 2308, 2403,  ..., 1699, 1600, 1385],\n",
            "        [1805, 2359,  379,  ...,  183,  838, 1179]])\n",
            "tensor([[  93, 2360, 2106,  ..., 2255,   36, 2058],\n",
            "        [ 948, 1952, 2462,  ..., 1479, 2292,  133],\n",
            "        [ 749, 1268, 2317,  ..., 1314,  452,  161],\n",
            "        ...,\n",
            "        [2186, 2559, 2186,  ...,  875,  911, 2572],\n",
            "        [1950,  566,  227,  ..., 2656, 1424, 1002],\n",
            "        [1000,  488,  768,  ..., 2136, 1990, 2520]]) tensor([[  93,  247,  440,  ..., 1544, 2455,  619],\n",
            "        [ 948, 2471, 2531,  ..., 1960, 1521, 2616],\n",
            "        [ 749,  647, 1510,  ..., 1335, 1858,  326],\n",
            "        ...,\n",
            "        [2300, 1568, 2484,  ...,  406, 1412, 1021],\n",
            "        [ 427, 1430, 1184,  ..., 2655, 1342, 2557],\n",
            "        [ 984,  390,  515,  ..., 2621,  268, 1290]])\n",
            "tensor([[ 588, 1515,  588,  ..., 1762,  882, 1768],\n",
            "        [ 409,  307,  409,  ...,  366, 1724,  366],\n",
            "        [1929, 1586,  953,  ..., 1214, 1547, 1853],\n",
            "        ...,\n",
            "        [ 152,  970, 1970,  ...,  461, 2008,  840],\n",
            "        [1656, 2045, 2545,  ..., 1438,  860,  354],\n",
            "        [ 774, 1595, 2271,  ..., 2286, 1317, 1262]]) tensor([[ 588, 1976, 1627,  ...,  164,  561, 1185],\n",
            "        [ 409, 1653, 1311,  ..., 2620, 2297, 2030],\n",
            "        [1929, 2458, 1716,  ..., 1832, 2102,  291],\n",
            "        ...,\n",
            "        [1561, 2418,  188,  ...,  319,  818,  611],\n",
            "        [  89,  763, 1044,  ..., 1457, 2553,  910],\n",
            "        [ 205, 1950, 1535,  ..., 1927,  301, 1313]])\n",
            "tensor([[ 510,  354, 2395,  ..., 2433,  897,   34],\n",
            "        [ 709, 2616, 1925,  ..., 1128,  309, 2534],\n",
            "        [1599,  606,  365,  ..., 2398,  965, 2398],\n",
            "        ...,\n",
            "        [1927, 2472, 1808,  ..., 1684, 2296,  506],\n",
            "        [1421, 1829, 2113,  ...,  668, 2349,  668],\n",
            "        [1327,  282, 1742,  ...,  935, 1623,  315]]) tensor([[ 510, 2700,  439,  ...,  632,  684, 2314],\n",
            "        [ 709, 1723,  158,  ..., 1359, 2007, 2499],\n",
            "        [1599, 1373,  943,  ..., 2332,  965,  553],\n",
            "        ...,\n",
            "        [ 988, 1449, 1482,  ..., 2601,  249,  800],\n",
            "        [1709,   72,   91,  ...,  173,  662, 1958],\n",
            "        [ 849, 1822, 1593,  ...,  629, 1982, 2492]])\n",
            "tensor([[2042, 2181,  642,  ..., 2032,  475, 2032],\n",
            "        [2394,  455, 1509,  ..., 2156, 1774, 2156],\n",
            "        [1981, 2707,  985,  ..., 2394, 1116, 1565],\n",
            "        ...,\n",
            "        [ 607, 1460,  842,  ..., 1586, 1929, 1586],\n",
            "        [1720, 2264, 2216,  ..., 2503, 1518, 2503],\n",
            "        [1560, 1547,  724,  ..., 1562, 1040, 1126]]) tensor([[2042, 1699, 2650,  ...,  222, 1870, 1230],\n",
            "        [2394, 1730, 2548,  ...,  536, 1663,  289],\n",
            "        [1981, 2160,  543,  ...,  437,   13, 1251],\n",
            "        ...,\n",
            "        [2374, 2104, 1137,  ..., 2215, 2447, 2577],\n",
            "        [ 640, 1850, 2245,  ..., 2335, 1247, 2102],\n",
            "        [ 965, 2606,  718,  ..., 1703,  338, 1713]])\n",
            "tensor([[1471,  820, 2589,  ..., 2423, 1095,  197],\n",
            "        [2003,  903, 2229,  ...,  532,  157, 1281],\n",
            "        [ 491, 2243,  941,  ..., 1208, 1033,   18],\n",
            "        ...,\n",
            "        [1986, 1161, 1611,  ..., 1942, 2154, 1172],\n",
            "        [2121, 2238, 2334,  ...,   55, 2023,   55],\n",
            "        [ 918, 2259,  871,  ..., 1760,  954,  660]]) tensor([[1471, 2589,  676,  ...,  555, 2566,  796],\n",
            "        [2003,  693,  474,  ..., 1303, 1746,   65],\n",
            "        [ 491, 1181,  209,  ...,  968,   15,  595],\n",
            "        ...,\n",
            "        [1162, 2112, 2249,  ...,  896, 2077,  949],\n",
            "        [1605,  885, 1261,  ..., 1165, 2186, 1925],\n",
            "        [ 699, 2512, 1521,  ..., 1056,  396, 2159]])\n",
            "tensor([[2593, 2643, 1902,  ..., 2483,  558, 1197],\n",
            "        [1286, 1122, 1977,  ...,  500,   86, 2374],\n",
            "        [1810,  715, 1007,  ..., 2278, 2508,  164],\n",
            "        ...,\n",
            "        [1025,   64, 2609,  ..., 2450,  467,  979],\n",
            "        [2349, 1625, 1067,  ..., 1472,  364,  375],\n",
            "        [ 173,  809, 1604,  ...,  554,  684, 1912]]) tensor([[2593, 2160, 1924,  ...,  852, 2355,  852],\n",
            "        [1286, 2623,  715,  ...,  799, 2673, 1517],\n",
            "        [1810,  977, 1020,  ..., 2412,  413, 2342],\n",
            "        ...,\n",
            "        [ 273, 2704, 2085,  ..., 1787, 2147,  411],\n",
            "        [1932,  792,  854,  ...,  310, 1525, 1013],\n",
            "        [ 471, 2061, 1648,  ...,  257, 2390,  901]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-fd7a73a000b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmin_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m#acc = test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-fd7a73a000b8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7ff8ba8d9d50>> (for post_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test():\n",
        "  model.eval()\n",
        "  z = model()\n",
        "  # acc = model.test(z[data.train_mask], data.y[data.train_mask],z[data.test_mask], data.y[data.test_mask],max_iter=10)\n",
        "  print(type(data.y))\n",
        "  print(type(z))\n",
        "  acc = model.test(z[data.train_mask], data.y[data.train_mask],z[data.test_mask], data.y[data.test_mask],max_iter=10)\n",
        "                  \n",
        "  score, eid = test()\n",
        "  result = {\"id\": eid,\n",
        "        \"prob\": acc}\n",
        "  result = pd.DataFrame(result)\n",
        "  result.to_csv(f'/content/drive/My Drive/dataset/result_node2vec{d}.csv',index=False)\n",
        "  return acc\n",
        "test()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "PWW8ql8h08s2",
        "outputId": "6d5912df-30e3-49c4-b61d-8061152d705a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.nn.parameter.Parameter'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-7362ca618bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/My Drive/dataset/result_node2vec{d}.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-7362ca618bfc>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-423c5d406775>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, train_z, train_y, test_z, test_y, solver, multi_class, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n\u001b[1;32m    158\u001b[0m                                  \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                                                train_y.detach().cpu().numpy())\n\u001b[0m\u001b[1;32m    160\u001b[0m         return clf.score(test_z.detach().cpu().numpy(),\n\u001b[1;32m    161\u001b[0m                          test_y.detach().cpu().numpy())\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## node2vecc"
      ],
      "metadata": {
        "id": "9B8kMuxMCv3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "p = 1.0\n",
        "q = 1.0\n",
        "dimensions = 128\n",
        "num_walks = 10\n",
        "walk_length = 80\n",
        "window_size = 10\n",
        "num_iter = 1\n",
        "workers = multiprocessing.cpu_count()"
      ],
      "metadata": {
        "id": "2XcsESseCyQi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stellargraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiGSKZLrDFtb",
        "outputId": "0286e1ca-13ba-43db-90c0-81000c32129a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stellargraph\n",
            "  Downloading stellargraph-1.2.1-py3-none-any.whl (435 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 435 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (1.3.5)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (2.6.3)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (3.2.2)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (2.8.0)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from stellargraph) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->stellargraph) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->stellargraph) (5.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->stellargraph) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->stellargraph) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->stellargraph) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->stellargraph) (3.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.44.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (57.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (13.0.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.24.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.5.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->stellargraph) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.1.0->stellargraph) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->stellargraph) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, stellargraph\n",
            "Successfully installed stellargraph-1.2.1 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stellargraph.data import BiasedRandomWalk\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "def node2vec_embedding(graph, name):\n",
        "    rw = BiasedRandomWalk(graph)\n",
        "    walks = rw.run(graph.nodes(), n=num_walks, length=walk_length, p=p, q=q)\n",
        "    print(f\"Number of random walks for '{name}': {len(walks)}\")\n",
        "\n",
        "    model = Word2Vec(\n",
        "        walks,\n",
        "        size=dimensions,\n",
        "        window=window_size,\n",
        "        min_count=0,\n",
        "        sg=1,\n",
        "        workers=workers,\n",
        "        iter=num_iter,\n",
        "    )\n",
        "\n",
        "    def get_embedding(u):\n",
        "        return model.wv[u]\n",
        "\n",
        "    return get_embedding"
      ],
      "metadata": {
        "id": "oDU5wIDXC9lr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "graph = nx.Graph()"
      ],
      "metadata": {
        "id": "ZfOxEJ28DgW7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#G.add_nodes_from(data.edge_index)\n",
        "print(data.edge_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zvYBhhYEA4G",
        "outputId": "0ebc1958-66bf-48df-ef53-89b705120b19"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2399, 2397,  854,  ..., 1711, 2440, 1222],\n",
            "        [2339, 1144, 1726,  ...,  171,  633,  122]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from stellargraph import StellarGraph\n",
        "# print(data.edge_index[0])\n",
        "# print(data.edge_index[1][1])\n",
        "graph = nx.Graph()\n",
        "graph.add_nodes_from(range(0, 2707))\n",
        "# print(data.edge_index[0])\n",
        "# for i in range(len(data.edge_index[0])):\n",
        "  # print([data.edge_index[0][i], data.edge_index[1][i]])\n"
      ],
      "metadata": {
        "id": "395bynz8NiNx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data.edge_index[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOVCFOsSZoqu",
        "outputId": "4ac75657-71cf-4703-a03c-7981c4fae442"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(np.shape(data.edge_index))\n",
        "edge = np.array(data.edge_index)\n",
        "print(edge[0][i], edge[1][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbJwxnqXbLGL",
        "outputId": "d1dbfc5c-dfb9-463e-e33c-dce7eb8968a7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2399 2339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stellargraph import StellarGraph\n",
        "# print(data.edge_index[0])\n",
        "# print(data.edge_index[1][1])\n",
        "graph = nx.Graph()\n",
        "graph.add_nodes_from(range(0, 2707))\n",
        "print(graph)\n",
        "for i in range(17372):\n",
        "  graph.add_edge(edge[0][i], edge[1][i])\n",
        "  # print([data.edge_index[0][i], data.edge_index[1][i]])\n",
        "  # graph.add_edges_from([data.edge_index[0][i], data.edge_index[1][i]])\n",
        "print(graph)\n",
        "graph = graph.to_undirected()\n",
        "# print(graph)\n",
        "graph = StellarGraph.from_networkx(graph)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZHi_IccEFx5",
        "outputId": "2f80e259-b8e0-4a93-b83f-4f5c59cb692c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 2707 nodes and 0 edges\n",
            "Graph with 2708 nodes and 8596 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stellargraph.data import EdgeSplitter\n",
        "from collections import Counter\n",
        "import multiprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Define an edge splitter on the original graph:\n",
        "\n",
        "edge_splitter_test = EdgeSplitter(graph)\n",
        "\n",
        "# Randomly sample a fraction p=0.1 of all positive links, and same number of negative links, from graph, and obtain the\n",
        "# reduced graph graph_test with the sampled links removed:\n",
        "graph_test, examples_test, labels_test = edge_splitter_test.train_test_split(\n",
        "    p=0.1, method=\"global\"\n",
        ")\n",
        "\n",
        "print(graph_test.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INW2gdtrFj3y",
        "outputId": "b61a1972-6145-4c1a-89ba-7cbaa6223adb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Sampled 859 positive and 859 negative edges. **\n",
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 2708, Edges: 7737\n",
            "\n",
            " Node types:\n",
            "  default: [2708]\n",
            "    Features: none\n",
            "    Edge types: default-default->default\n",
            "\n",
            " Edge types:\n",
            "    default-default->default: [7737]\n",
            "        Weights: all 1 (default)\n",
            "        Features: none\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the same process to compute a training subset from within the test graph\n",
        "edge_splitter_train = EdgeSplitter(graph_test, graph)\n",
        "graph_train, examples, labels = edge_splitter_train.train_test_split(\n",
        "    p=0.1, method=\"global\"\n",
        ")\n",
        "(\n",
        "    examples_train,\n",
        "    examples_model_selection,\n",
        "    labels_train,\n",
        "    labels_model_selection,\n",
        ") = train_test_split(examples, labels, train_size=0.75, test_size=0.25)\n",
        "\n",
        "print(graph_train.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZFddVhjGM6R",
        "outputId": "d3af9d38-a0fe-4cca-ee5f-6352a353b626"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Sampled 773 positive and 773 negative edges. **\n",
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 2708, Edges: 6964\n",
            "\n",
            " Node types:\n",
            "  default: [2708]\n",
            "    Features: none\n",
            "    Edge types: default-default->default\n",
            "\n",
            " Edge types:\n",
            "    default-default->default: [6964]\n",
            "        Weights: all 1 (default)\n",
            "        Features: none\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(\n",
        "    [\n",
        "        (\n",
        "            \"Training Set\",\n",
        "            len(examples_train),\n",
        "            \"Train Graph\",\n",
        "            \"Test Graph\",\n",
        "            \"Train the Link Classifier\",\n",
        "        ),\n",
        "        (\n",
        "            \"Model Selection\",\n",
        "            len(examples_model_selection),\n",
        "            \"Train Graph\",\n",
        "            \"Test Graph\",\n",
        "            \"Select the best Link Classifier model\",\n",
        "        ),\n",
        "        (\n",
        "            \"Test set\",\n",
        "            len(examples_test),\n",
        "            \"Test Graph\",\n",
        "            \"Full Graph\",\n",
        "            \"Evaluate the best Link Classifier\",\n",
        "        ),\n",
        "    ],\n",
        "    columns=(\"Split\", \"Number of Examples\", \"Hidden from\", \"Picked from\", \"Use\"),\n",
        ").set_index(\"Split\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "PqRHNXpgGAv9",
        "outputId": "eba58a39-2279-421f-a9fd-0732cfdd296b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Number of Examples  Hidden from Picked from  \\\n",
              "Split                                                          \n",
              "Training Set                   1159  Train Graph  Test Graph   \n",
              "Model Selection                 387  Train Graph  Test Graph   \n",
              "Test set                       1718   Test Graph  Full Graph   \n",
              "\n",
              "                                                   Use  \n",
              "Split                                                   \n",
              "Training Set                 Train the Link Classifier  \n",
              "Model Selection  Select the best Link Classifier model  \n",
              "Test set             Evaluate the best Link Classifier  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea7cb4d3-8714-451b-b7e1-93134684ffa0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number of Examples</th>\n",
              "      <th>Hidden from</th>\n",
              "      <th>Picked from</th>\n",
              "      <th>Use</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Split</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Training Set</th>\n",
              "      <td>1159</td>\n",
              "      <td>Train Graph</td>\n",
              "      <td>Test Graph</td>\n",
              "      <td>Train the Link Classifier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model Selection</th>\n",
              "      <td>387</td>\n",
              "      <td>Train Graph</td>\n",
              "      <td>Test Graph</td>\n",
              "      <td>Select the best Link Classifier model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Test set</th>\n",
              "      <td>1718</td>\n",
              "      <td>Test Graph</td>\n",
              "      <td>Full Graph</td>\n",
              "      <td>Evaluate the best Link Classifier</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea7cb4d3-8714-451b-b7e1-93134684ffa0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea7cb4d3-8714-451b-b7e1-93134684ffa0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea7cb4d3-8714-451b-b7e1-93134684ffa0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = 1.0\n",
        "q = 1.0\n",
        "dimensions = 128\n",
        "num_walks = 10\n",
        "walk_length = 80\n",
        "window_size = 10\n",
        "num_iter = 1\n",
        "workers = multiprocessing.cpu_count()"
      ],
      "metadata": {
        "id": "n4zOWOHeGTGD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stellargraph.data import BiasedRandomWalk\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "def node2vec_embedding(graph, name):\n",
        "    rw = BiasedRandomWalk(graph)\n",
        "    walks = rw.run(graph.nodes(), n=num_walks, length=walk_length, p=p, q=q)\n",
        "    print(f\"Number of random walks for '{name}': {len(walks)}\")\n",
        "\n",
        "    model = Word2Vec(\n",
        "        walks,\n",
        "        size=dimensions,\n",
        "        window=window_size,\n",
        "        min_count=0,\n",
        "        sg=1,\n",
        "        workers=workers,\n",
        "        iter=num_iter,\n",
        "    )\n",
        "\n",
        "    def get_embedding(u):\n",
        "        return model.wv[u]\n",
        "\n",
        "    return get_embedding"
      ],
      "metadata": {
        "id": "zcBoK4r9GWkK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_train = node2vec_embedding(graph_train, \"Train Graph\")"
      ],
      "metadata": {
        "id": "14xxRexgHPLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# 1. link embeddings\n",
        "def link_examples_to_features(link_examples, transform_node, binary_operator):\n",
        "    return [\n",
        "        binary_operator(transform_node(src), transform_node(dst))\n",
        "        for src, dst in link_examples\n",
        "    ]\n",
        "\n",
        "\n",
        "# 2. training classifier\n",
        "def train_link_prediction_model(\n",
        "    link_examples, link_labels, get_embedding, binary_operator\n",
        "):\n",
        "    clf = link_prediction_classifier()\n",
        "    link_features = link_examples_to_features(\n",
        "        link_examples, get_embedding, binary_operator\n",
        "    )\n",
        "    clf.fit(link_features, link_labels)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def link_prediction_classifier(max_iter=2000):\n",
        "    lr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring=\"roc_auc\", max_iter=max_iter)\n",
        "    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n",
        "\n",
        "\n",
        "# 3. and 4. evaluate classifier\n",
        "def evaluate_link_prediction_model(\n",
        "    clf, link_examples_test, link_labels_test, get_embedding, binary_operator\n",
        "):\n",
        "    link_features_test = link_examples_to_features(\n",
        "        link_examples_test, get_embedding, binary_operator\n",
        "    )\n",
        "    score = evaluate_roc_auc(clf, link_features_test, link_labels_test)\n",
        "    return score\n",
        "\n",
        "\n",
        "def evaluate_roc_auc(clf, link_features, link_labels):\n",
        "    predicted = clf.predict_proba(link_features)\n",
        "\n",
        "    # check which class corresponds to positive links\n",
        "    positive_column = list(clf.classes_).index(1)\n",
        "    return roc_auc_score(link_labels, predicted[:, positive_column])"
      ],
      "metadata": {
        "id": "R2_DZLd1b_H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def operator_hadamard(u, v):\n",
        "    return u * v\n",
        "\n",
        "\n",
        "def operator_l1(u, v):\n",
        "    return np.abs(u - v)\n",
        "\n",
        "\n",
        "def operator_l2(u, v):\n",
        "    return (u - v) ** 2\n",
        "\n",
        "\n",
        "def operator_avg(u, v):\n",
        "    return (u + v) / 2.0\n",
        "\n",
        "\n",
        "def run_link_prediction(binary_operator):\n",
        "    clf = train_link_prediction_model(\n",
        "        examples_train, labels_train, embedding_train, binary_operator\n",
        "    )\n",
        "    score = evaluate_link_prediction_model(\n",
        "        clf,\n",
        "        examples_model_selection,\n",
        "        labels_model_selection,\n",
        "        embedding_train,\n",
        "        binary_operator,\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"classifier\": clf,\n",
        "        \"binary_operator\": binary_operator,\n",
        "        \"score\": score,\n",
        "    }\n",
        "\n",
        "\n",
        "binary_operators = [operator_hadamard, operator_l1, operator_l2, operator_avg]"
      ],
      "metadata": {
        "id": "cyBUklZrcCKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = [run_link_prediction(op) for op in binary_operators]\n",
        "best_result = max(results, key=lambda result: result[\"score\"])\n",
        "\n",
        "print(f\"Best result from '{best_result['binary_operator'].__name__}'\")\n",
        "\n",
        "pd.DataFrame(\n",
        "    [(result[\"binary_operator\"].__name__, result[\"score\"]) for result in results],\n",
        "    columns=(\"name\", \"ROC AUC score\"),\n",
        ").set_index(\"name\")"
      ],
      "metadata": {
        "id": "3F8rmRzPcFWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "IHQXSSYLg2A2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMmjInbH6wG4"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        # cosine similarity\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim = -1)\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        return (prob_adj > 0).nonzero(as_tuple = False).t()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_channel = np.shape(attr[0])[0]\n",
        "model = Net(in_channel, 128, 1)\n",
        "print(model)\n",
        "# optimizer = torch.optim.Adam(params = model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "lLpRfabkgRbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fd29b9-4358-4a87-ed07-0fb541989160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): GCNConv(1433, 128)\n",
            "  (conv2): GCNConv(128, 1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_examples = total_loss = 0\n",
        "# wandb.watch(model)\n",
        "# wandb.init(project=\"Link Prediction\") \n",
        "\n",
        "def train():\n",
        "    threshold = torch.tensor([0.4])\n",
        "    min_valid_loss = 1\n",
        "    model.train()\n",
        "    for epoch in range(epocht):\n",
        "          optimizer.zero_grad()\n",
        "          z = model.encode(data.x, data.pos_edge_index)\n",
        "          out = model.decode(z, data.edge_index).view(-1)\n",
        "          s_predict = out.sigmoid()                   \n",
        "          loss = criterion(out, torch.FloatTensor(data.y))\n",
        "          predicted = (s_predict > threshold).float()\n",
        "          f1score = f1_score(predicted.detach().numpy(), data.y.astype(float))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if epoch % 100 == 0:\n",
        "            wandb.log({'pair_loss': loss, 'epoch': epoch})\n",
        "            wandb.log({'f1score': f1score, 'epoch': epoch})\n",
        "            print(f'epoch: {epoch} / training loss: {loss} /  f1score {f1score}')\n",
        "            if min_valid_loss > loss:\n",
        "              min_valid_loss = loss\n",
        "            # Saving State Dict\n",
        "              torch.save(model.state_dict(), '/content/drive/My Drive/dataset/saved_model.pth')"
      ],
      "metadata": {
        "id": "g3adCzuWmr2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350,
          "referenced_widgets": [
            "5d0b2f8487f44f678c643796623853dc",
            "97a50fa9304f4a0582c75ff6bf56a11a",
            "edf85c7983e648269ee3d1f35fa86c1b",
            "bfa1d72f9d3d4fa8a9138543dd019765",
            "cafd96d3cce445dcab9dfd37549d30c7",
            "18393e33e3bc44f1979d32a4761e4dd3",
            "6d387b71e6334f539884761069906e1c",
            "fc8dd4ae1e6840178f2ba02ba9b7880e"
          ]
        },
        "outputId": "e4dbe65e-74b4-4569-bbbc-041950c24f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:3eihp5jk) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d0b2f8487f44f678c643796623853dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇██</td></tr><tr><td>f1score</td><td>▁▁▅▆▇▇▇▇▇▇█████</td></tr><tr><td>pair_loss</td><td>█▇▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1400</td></tr><tr><td>f1score</td><td>0.78124</td></tr><tr><td>pair_loss</td><td>0.43426</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">deep-cloud-13</strong>: <a href=\"https://wandb.ai/imhilaryy1999/Link%20Prediction/runs/3eihp5jk\" target=\"_blank\">https://wandb.ai/imhilaryy1999/Link%20Prediction/runs/3eihp5jk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220412_012503-3eihp5jk/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:3eihp5jk). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220412_012738-3idr60oo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/imhilaryy1999/Link%20Prediction/runs/3idr60oo\" target=\"_blank\">pretty-pine-14</a></strong> to <a href=\"https://wandb.ai/imhilaryy1999/Link%20Prediction\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "LbxCzPH-oQDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179ee43c-6b2b-4542-a190-ed3ff92df888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 / training loss: 0.6924976110458374 /  f1score 0.6647194465795542\n",
            "epoch: 100 / training loss: 0.480236291885376 /  f1score 0.7647218453188602\n",
            "epoch: 200 / training loss: 0.43853479623794556 /  f1score 0.7771759432200225\n",
            "epoch: 300 / training loss: 0.4180329144001007 /  f1score 0.7830277830277831\n",
            "epoch: 400 / training loss: 0.405199259519577 /  f1score 0.7834738936795224\n",
            "epoch: 500 / training loss: 0.39701104164123535 /  f1score 0.7850218589621745\n",
            "epoch: 600 / training loss: 0.39153310656547546 /  f1score 0.7876477316050323\n",
            "epoch: 700 / training loss: 0.3872314989566803 /  f1score 0.7876993601375227\n",
            "epoch: 800 / training loss: 0.38407137989997864 /  f1score 0.7872645568409982\n",
            "epoch: 900 / training loss: 0.3818592429161072 /  f1score 0.7864374403056351\n",
            "epoch: 1000 / training loss: 0.38200297951698303 /  f1score 0.7849164677804297\n",
            "epoch: 1100 / training loss: 0.37731513381004333 /  f1score 0.7875489353575862\n",
            "epoch: 1200 / training loss: 0.3771909773349762 /  f1score 0.7864802757564151\n",
            "epoch: 1300 / training loss: 0.3751147985458374 /  f1score 0.7868005738880918\n",
            "epoch: 1400 / training loss: 0.37302887439727783 /  f1score 0.7882027297890616\n",
            "epoch: 1500 / training loss: 0.3718412518501282 /  f1score 0.7884395268981306\n",
            "epoch: 1600 / training loss: 0.37166306376457214 /  f1score 0.7883658629927287\n",
            "epoch: 1700 / training loss: 0.3695809245109558 /  f1score 0.7895439801564587\n",
            "epoch: 1800 / training loss: 0.3688587546348572 /  f1score 0.789045293498037\n",
            "epoch: 1900 / training loss: 0.3679811954498291 /  f1score 0.7895139686184462\n",
            "epoch: 2000 / training loss: 0.36775967478752136 /  f1score 0.7879308698558197\n",
            "epoch: 2100 / training loss: 0.3668299615383148 /  f1score 0.7883825355880386\n",
            "epoch: 2200 / training loss: 0.36637625098228455 /  f1score 0.7888942077549066\n",
            "epoch: 2300 / training loss: 0.36556631326675415 /  f1score 0.7888400535065928\n",
            "epoch: 2400 / training loss: 0.3659456670284271 /  f1score 0.7874664622460713\n",
            "epoch: 2500 / training loss: 0.3643485903739929 /  f1score 0.7887593194417893\n",
            "epoch: 2600 / training loss: 0.3639874756336212 /  f1score 0.789176785543551\n",
            "epoch: 2700 / training loss: 0.36306464672088623 /  f1score 0.7899674516561364\n",
            "epoch: 2800 / training loss: 0.3627508580684662 /  f1score 0.788527724665392\n",
            "epoch: 2900 / training loss: 0.3615224063396454 /  f1score 0.788743179860247\n",
            "epoch: 3000 / training loss: 0.36187729239463806 /  f1score 0.7897406450378026\n",
            "epoch: 3100 / training loss: 0.3626960217952728 /  f1score 0.7881811204911743\n",
            "epoch: 3200 / training loss: 0.3608911633491516 /  f1score 0.7898113568897827\n",
            "epoch: 3300 / training loss: 0.35992833971977234 /  f1score 0.7898211039892854\n",
            "epoch: 3400 / training loss: 0.3609529137611389 /  f1score 0.7893175074183977\n",
            "epoch: 3500 / training loss: 0.36273637413978577 /  f1score 0.7877625395607558\n",
            "epoch: 3600 / training loss: 0.35960689187049866 /  f1score 0.7896148687488025\n",
            "epoch: 3700 / training loss: 0.3592985272407532 /  f1score 0.7899224063607625\n",
            "epoch: 3800 / training loss: 0.35861682891845703 /  f1score 0.7901589125023932\n",
            "epoch: 3900 / training loss: 0.3581772446632385 /  f1score 0.7906175203446625\n",
            "epoch: 4000 / training loss: 0.3578248918056488 /  f1score 0.7913875598086125\n",
            "epoch: 4100 / training loss: 0.3576764464378357 /  f1score 0.7913476263399694\n",
            "epoch: 4200 / training loss: 0.35855334997177124 /  f1score 0.7880356629278112\n",
            "epoch: 4300 / training loss: 0.35691943764686584 /  f1score 0.7909961685823755\n",
            "epoch: 4400 / training loss: 0.35772284865379333 /  f1score 0.7882093980285195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkcPsMiYxSwy"
      },
      "source": [
        "## Testing "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class load_data():\n",
        "    def __init__(self, ):\n",
        "        super(load_data, self).__init__()\n",
        "        self.data = {}\n",
        "\n",
        "    def read_data(self,path):\n",
        "        file = pd.read_csv(path)\n",
        "        label = file.loc[:, 'label'].values\n",
        "        edgeto = file.loc[:, 'to'].values\n",
        "        edgefrom = file.loc[:, 'from'].values\n",
        "        pos_edge_index = [[], []]\n",
        "        non_zero = np.nonzero(np.array(label))[0]\n",
        "        # positive\n",
        "        pos_edge_index[0].extend(edgeto[non_zero])\n",
        "        pos_edge_index[1].extend(edgefrom[non_zero])\n",
        "        pos_edge_index[1].extend(edgeto[non_zero])\n",
        "        pos_edge_index[0].extend(edgefrom[non_zero])\n",
        "        edge_index = torch.tensor(pos_edge_index)\n",
        "        return edge_index\n",
        "\n",
        "    def read_test_data(self,path):\n",
        "        file = pd.read_csv(path)\n",
        "        edg_id = file.loc[:, 'id'].values\n",
        "        edgeto = file.loc[:, 'to'].values\n",
        "        edgefrom = file.loc[:, 'from'].values\n",
        "        edge_index = [[], []]\n",
        "        edge_index[0].extend(edgeto)\n",
        "        edge_index[1].extend(edgefrom)\n",
        "        test_edge_index = torch.tensor(edge_index)\n",
        "        return test_edge_index, edg_id\n",
        "\n",
        "    def read_content(self,path):\n",
        "        attribution = [];\n",
        "        node = []\n",
        "        content = pd.read_csv(path, delimiter='\\t', header=None)\n",
        "        contentArray = content.values\n",
        "        attribute = contentArray[contentArray[:, 0].argsort()]\n",
        "        for i in attribute:\n",
        "          n = i[0]\n",
        "          x = i[1:]\n",
        "          attribution.append(x)\n",
        "          node.append(n)\n",
        "        attribution = torch.tensor(attribution, dtype=torch.float)\n",
        "        node_num = np.shape(node)[0]\n",
        "        return attribution, node_num\n",
        "\n"
      ],
      "metadata": {
        "id": "mA9ydZVeQ65L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dt = load_data()\n",
        "pos_edge = Dt.read_data(train1_path)\n",
        "edge_index_test, eid_test = Dt.read_test_data(test1_path)\n",
        "attribution, node_num = Dt.read_content(content_path)\n",
        "\n",
        "data = Data(x=attribution, edge_index=pos_edge, edge_index_test = edge_index_test, edge_id = eid_test )\n",
        "edge_index= data.edge_index\n",
        "attr = data.x\n",
        "edge_index_test = data.edge_index_test\n",
        "edge_id = data.edge_id\n"
      ],
      "metadata": {
        "id": "UqW2Y7WXfXy4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "4c25e4be-27ea-4fa5-d4e1-7de95d137e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8f5356dad602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpos_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0medge_index_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mattribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_channel = np.shape(attr[0])[0]\n",
        "model = Net(in_channel, 128, 1)\n",
        "model_path = torch.load('/content/drive/My Drive/dataset/saved_model.pth')\n",
        "model.load_state_dict(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76naPPIzfc9A",
        "outputId": "9b35ff94-7516-4561-dc32-8c16333b08ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    scores = []; eid = []\n",
        "    z = model.encode(attr, edge_index)\n",
        "    out = model.decode(z, edge_index_test).view(-1).sigmoid()\n",
        "    scores.extend(out.numpy())\n",
        "    eid.extend(np.array(edge_id))\n",
        "    return scores, eid"
      ],
      "metadata": {
        "id": "aO3Eo4n7fefE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "score, eid = test()\n",
        "result = {\"id\": eid,\n",
        "          \"prob\":score}\n",
        "result = pd.DataFrame( result)\n",
        "result.to_csv(f'result{d}.csv',index=False)"
      ],
      "metadata": {
        "id": "cshTkwAafj5X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "link_prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d0b2f8487f44f678c643796623853dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97a50fa9304f4a0582c75ff6bf56a11a",
              "IPY_MODEL_edf85c7983e648269ee3d1f35fa86c1b"
            ],
            "layout": "IPY_MODEL_bfa1d72f9d3d4fa8a9138543dd019765"
          }
        },
        "97a50fa9304f4a0582c75ff6bf56a11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cafd96d3cce445dcab9dfd37549d30c7",
            "placeholder": "​",
            "style": "IPY_MODEL_18393e33e3bc44f1979d32a4761e4dd3",
            "value": "0.017 MB of 0.017 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "edf85c7983e648269ee3d1f35fa86c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d387b71e6334f539884761069906e1c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc8dd4ae1e6840178f2ba02ba9b7880e",
            "value": 1
          }
        },
        "bfa1d72f9d3d4fa8a9138543dd019765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cafd96d3cce445dcab9dfd37549d30c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18393e33e3bc44f1979d32a4761e4dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d387b71e6334f539884761069906e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc8dd4ae1e6840178f2ba02ba9b7880e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}