# -*- coding: utf-8 -*-
"""link_prediction.ipynb

Automatically generated by Colaboratory.

# Assignment 2 : link_prediction

## Download Package
"""

"""## Import Package"""

import torch
import torch.nn as nn
from torch.nn import Linear
from torch_geometric.nn import GCNConv
import csv
import numpy as np
import pprint

"""## dataset """

from pathlib import Path
import pandas as pd


class load_data():
    def __init__(self, ):
        super(load_data, self).__init__()
        self.data = {}

    def read_data(self,path):
        file = pd.read_csv(path)
        label = file.loc[:, 'label'].values
        bilabel = []
        bilabel.extend(label)
        bilabel.extend(label)
        bilabel = np.array(bilabel)
        edg_id = file.loc[:,'id'].values
        edgeto = file.loc[:, 'to'].values
        edgefrom = file.loc[:, 'from'].values

        edge_index = [[], []];
        pos_edge_index = [[], []]
        non_zero = np.nonzero(np.array(label))[0]
        edge_index[0].extend(edgeto)
        edge_index[1].extend(edgefrom)
        edge_index[1].extend(edgeto)
        edge_index[0].extend(edgefrom)
        edge_index = torch.tensor(edge_index)
        # positive
        pos_edge_index[0].extend(edgeto[non_zero])
        pos_edge_index[1].extend(edgefrom[non_zero])
        pos_edge_index[1].extend(edgeto[non_zero])
        pos_edge_index[0].extend(edgefrom[non_zero])
        pos_edge_index = torch.tensor(pos_edge_index)

        return edge_index, pos_edge_index, bilabel

    def read_test_data(self,path):
        file = pd.read_csv(path)
        edg_id = file.loc[:, 'id'].values
        edgeto = file.loc[:, 'to'].values
        edgefrom = file.loc[:, 'from'].values
        edge_index = [[], []]
        edge_index[0].extend(edgeto)
        edge_index[1].extend(edgefrom)
        edge_index = torch.tensor(edge_index)
        return edge_index, edg_id

    def read_content(self,path):
        attribution = [];
        node = []
        content = pd.read_csv(path, delimiter='\t', header=None)
        contentArray = content.values
        attribute = contentArray[contentArray[:, 0].argsort()]
        for i in attribute:
            n = i[0]
            x = i[1:]
            attribution.append(x)
            node.append(n)
        attribution = torch.tensor(attribution, dtype=torch.float)
        node_num = np.shape(node)[0]
        return attribution, node_num


"""# Model"""

from torch_geometric.nn import GCNConv


class Net(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, out_channels)

    def encode(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        return self.conv2(x, edge_index)

    def decode(self, z, edge_label_index):
        # cosine similarity
        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)

    def decode_all(self, z):
        prob_adj = z @ z.t()
        return (prob_adj > 0).nonzero(as_tuple=False).t()


from torch_geometric.data import Data

import os

d = 3
train1_path = f"dataset{d}/train.csv"
test1_path = f"dataset{d}/test.csv"
content_path = f"dataset{d}/content.csv"

# Dtest= read_test_data(test1_path)
Dt = load_data()
edge_index, pos_edge, label = Dt.read_data(train1_path)
edge_index_test, eid_test = Dt.read_test_data(test1_path)
D = load_data()
attribution, node_num = D.read_content(content_path)

data = Data( x=attribution, edge_index=edge_index, pos_edge_index=pos_edge,edge_index_test = edge_index_test, y=label, num_nodes=node_num,edge_id = eid_test )
edge_index= data.edge_index
attr = data.x
edge_index_test =data.edge_index_test
edge_id = data.edge_id

in_channel = np.shape(attr[0])[0]
# attr.shape
model = Net(in_channel, 128, 1)
model_path = torch.load('saved_model.pth')
model.load_state_dict(model_path)
# print(model)
# optimizer = torch.optim.Adam(params = model.parameters(), lr=0.001, weight_decay=5e-4)
optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001, weight_decay=3e-4)

criterion = torch.nn.BCEWithLogitsLoss()

import wandb
from sklearn.metrics import f1_score

"""## Testing """


model
@torch.no_grad()
def test():
    model.eval()
    scores = []; eid = []
    z = model.encode(attr, edge_index)
    out = model.decode(z, edge_index_test).view(-1).sigmoid()
    scores.extend(out.numpy())
    eid.extend(np.array(edge_id))
    return scores, eid

if __name__ == '__main__':
    score, eid = test()
    result = {"id": eid,
              "prob":score}
    result = pd.DataFrame( result)
    result.to_csv(f'result{d}.csv',index=False)
